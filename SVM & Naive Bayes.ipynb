{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Question 1: What is a Support Vector Machine (SVM), and how does it\n",
    "> work? ANS 1 :-\n",
    ">\n",
    "> **Support Vector Machine (SVM)**  \n",
    "> A **Support Vector Machine (SVM)** is a **supervised machine learning\n",
    "> algorithm** used for **classification** and sometimes **regression**\n",
    "> tasks.​  \n",
    "> It is especially powerful for **binary classification problems**\n",
    "> (e.g., classifying emails as *spam* or *not spam*).\n",
    ">\n",
    "> **How SVM Works**  \n",
    "> 1.​ **Separating Data with a Hyperplane​**  \n",
    "> ○​ Imagine you have data points belonging to two classes (e.g., red and\n",
    "> blue points).​  \n",
    "> ○​ SVM tries to find the **best boundary (hyperplane)** that separates\n",
    "> these two classes.​  \n",
    "> ○​ In 2D, this hyperplane is just a line; in 3D, it’s a plane; in\n",
    "> higher dimensions, it’s called a hyperplane.​\n",
    ">\n",
    "> 2.​ **Maximizing the Margin​**  \n",
    "> ○​ Instead of just drawing any line, SVM chooses the line that\n",
    "> **maximizes the** **margin**, i.e., the distance between the line and\n",
    "> the nearest data points from each class.​  \n",
    "> ○​ These nearest data points are called **support vectors** (hence the\n",
    "> name!).​\n",
    ">\n",
    "> 3.​ **Handling Non-Linear Data​**  \n",
    "> ○​ Sometimes, the data is not linearly separable (can’t be split with a\n",
    "> straight line).​ ○​ In such cases, SVM uses the **Kernel Trick** to map\n",
    "> the data into a  \n",
    "> higher-dimensional space where it becomes separable.​\n",
    ">\n",
    "> ○​ Common kernels:​  \n",
    "> ■​ **Linear Kernel** – works for linearly separable data.​  \n",
    "> ■​ **Polynomial Kernel** – separates curved boundaries.​  \n",
    "> ■​ **RBF (Radial Basis Function) Kernel** – good for complex non-linear\n",
    "> data.​\n",
    ">\n",
    "> 4.​ **Soft Margin for Noisy Data​**  \n",
    "> ○​ Real-world data often has noise or overlapping points.​  \n",
    "> ○​ SVM allows some misclassifications using a **soft margin**\n",
    "> controlled by a parameter **C**.​  \n",
    "> ○​ A small C → wider margin, allows more errors (good for\n",
    "> generalization).​ ○​ A large C → stricter separation, fewer errors but\n",
    "> may overfit.​\n",
    ">\n",
    "> **Intuition with Example**  \n",
    "> Imagine you want to separate **cats vs dogs** based on features like\n",
    "> weight and height: ●​ SVM finds the line (in 2D) or plane (in higher\n",
    "> dimensions) that separates them with the **maximum possible gap**.​  \n",
    "> ●​ The animals closest to that boundary are the **support vectors**.​  \n",
    "> ●​ Even if there’s some overlap, SVM can allow small mistakes but still\n",
    "> focus on a strong separation rule.​\n",
    ">\n",
    "> **Business Value of SVM**  \n",
    "> SVM is widely used in:\n",
    ">\n",
    "> ●​ **Healthcare** → disease classification (cancer detection, diabetes\n",
    "> prediction).​●​ **Finance** → fraud detection, credit risk analysis.​  \n",
    "> ●​ **Text classification** → spam detection, sentiment analysis.​  \n",
    "> ●​ **Image recognition** → face recognition, handwriting recognition.\n",
    ">\n",
    "> Question 2: Explain the difference between Hard Margin and Soft Margin\n",
    "> SVM.\n",
    ">\n",
    "> ANS 2 :-  \n",
    "> **1. Hard Margin SVM**  \n",
    "> ●​ **Definition**: A hard margin SVM tries to find a hyperplane that\n",
    "> **perfectly separates** the data into classes **without any\n",
    "> misclassifications**.​  \n",
    "> ●​ **Assumptions**: Data must be **linearly separable** (no\n",
    "> overlaps).​  \n",
    "> ●​ **Behavior**:​  \n",
    "> ○​ No tolerance for errors or outliers.​  \n",
    "> ○​ Works well only for **clean datasets** with no noise.​  \n",
    "> ●​ **Limitation**:​  \n",
    "> ○​ If even one point is misclassified (an outlier), the hard margin SVM\n",
    "> may fail to find a solution.​\n",
    ">\n",
    "> **Best for:** Perfectly separable, noise-free data.\n",
    ">\n",
    "> **2. Soft Margin SVM**  \n",
    "> ●​ **Definition**: A soft margin SVM allows **some misclassifications**\n",
    "> or violations of the margin in order to achieve better\n",
    "> generalization.​  \n",
    "> ●​ **How it works**:​  \n",
    "> ○​ Introduces a **slack variable** (ξ) that allows some points to be on\n",
    "> the wrong side of the margin.​\n",
    ">\n",
    "> ○​ Controlled by a parameter **C** (regularization parameter).​  \n",
    "> ■​ High C → fewer misclassifications, stricter boundary (risk of\n",
    "> overfitting).​ ■​ Low C → more tolerance for errors, wider margin\n",
    "> (better generalization).​●​ **Advantage**:​  \n",
    "> ○​ Handles noisy and overlapping data.​  \n",
    "> ○​ More robust for real-world datasets.​\n",
    ">\n",
    "> **Best for:** Noisy, real-world data where perfect separation is not\n",
    "> possible.\n",
    ">\n",
    "> Question 3: What is the Kernel Trick in SVM? Give one example of a\n",
    "> kernel and explain its use case.\n",
    ">\n",
    "> ANS 3 ➖\n",
    ">\n",
    "> **What is the Kernel Trick in SVM?**\n",
    ">\n",
    "> ●​ Many datasets are **not linearly separable** (you can’t split them\n",
    "> with a straight line or flat hyperplane).​  \n",
    "> ●​ The **Kernel Trick** is a mathematical method that lets SVM\n",
    "> **project data into a**  \n",
    "> **higher-dimensional space** where it *becomes linearly separable*,\n",
    "> **without actually** **computing the transformation explicitly**.\n",
    ">\n",
    "> **How It Works**  \n",
    "> 1.​ Suppose your data looks like circles inside each other (not\n",
    "> linearly separable).​  \n",
    "> 2.​ If you map the data to a higher dimension (e.g., add a squared\n",
    "> feature), the classes may become linearly separable.​  \n",
    "> 3.​ The kernel function computes this mapping indirectly, avoiding\n",
    "> heavy computations.\n",
    ">\n",
    "> **Example of a Kernel: RBF (Radial Basis Function) Kernel** ●​\n",
    "> **Formula:​**  \n",
    "> K(x,x′)=exp⁡(−γ∥x−x′∥2)  \n",
    "> ●​ **Meaning:** Measures how close two points are.​\n",
    ">\n",
    "> ○​ If points are close, the kernel value is near **1**.​\n",
    ">\n",
    "> ○​ If far apart, the value approaches **0**.​\n",
    ">\n",
    "> **Use Case of RBF Kernel**\n",
    ">\n",
    "> ●​ **Non-linear data classification**: For example, in image\n",
    "> recognition (e.g., distinguishing between different handwritten digits\n",
    "> like \"3\" and \"8\"), the data is not linearly separable.​\n",
    ">\n",
    "> ●​ The **RBF kernel** transforms the data into a higher-dimensional\n",
    "> space where SVM can find a clear separating hyperplane.​\n",
    ">\n",
    "> ●​ This makes it one of the most commonly used kernels in real-world\n",
    "> problems.​\n",
    ">\n",
    "> Question 4: What is a Naïve Bayes Classifier, and why is it called\n",
    "> “naïve”? ANS 4 ➖\n",
    ">\n",
    "> **Naïve Bayes Classifier**\n",
    ">\n",
    "> The **Naïve Bayes Classifier** is a **supervised machine learning\n",
    "> algorithm** based on **Bayes’ Theorem**.​  \n",
    "> It is widely used for **classification tasks**, especially in **text\n",
    "> classification** (spam detection, sentiment analysis, document\n",
    "> categorization).\n",
    ">\n",
    "> **Why is it called “Naïve”?**\n",
    ">\n",
    "> It is called **naïve** because it makes a **strong assumption**:​  \n",
    "> All features (predictors) are **independent of each other** given the\n",
    "> class label.\n",
    ">\n",
    "> ●​ Example: In spam detection, features could be words like *“win”*,\n",
    "> *“offer”*, *“free”*.​\n",
    ">\n",
    "> ○​ Naïve Bayes assumes that the presence of *“win”* is independent of\n",
    "> *“offer”*, which in reality is not strictly true.​\n",
    ">\n",
    "> ○​ Despite this “naïve” assumption, the algorithm works **surprisingly\n",
    "> well** in practice.\n",
    ">\n",
    "> **Types of Naïve Bayes**\n",
    ">\n",
    "> 1.​ **Multinomial Naïve Bayes** → For discrete counts (e.g., word\n",
    "> frequencies in text).​\n",
    ">\n",
    "> 2.​ **Gaussian Naïve Bayes** → For continuous features (assumes\n",
    "> features follow a Gaussian distribution).​  \n",
    "> 3.​ **Bernoulli Naïve Bayes** → For binary/boolean features (e.g., word\n",
    "> present or not).​\n",
    ">\n",
    "> **Use Cases**  \n",
    "> ●​ **Email Spam Filtering** → Predict spam vs non-spam.​  \n",
    "> ●​ **Sentiment Analysis** → Classify reviews as positive or negative.​  \n",
    "> ●​ **Medical Diagnosis** → Classify whether a patient has a disease\n",
    "> based on symptoms. Question 5: Describe the Gaussian, Multinomial, and\n",
    "> Bernoulli Naïve Bayes variants. When would you use each one?\n",
    ">\n",
    "> ANS 5 :-\n",
    ">\n",
    "> **1. Gaussian Naïve Bayes**  \n",
    "> ●​ **Assumption**: Features follow a **continuous Gaussian (Normal)\n",
    "> distribution**.​ ●​ **How it works**: For each feature, it estimates\n",
    "> mean (μ) and variance (σ²) per class, and calculates the probability\n",
    "> using the Gaussian probability density function.​  \n",
    "> ●​ **When to use**:​  \n",
    "> ○​ When your features are **continuous values** (real numbers).​  \n",
    "> ○​ Example:​  \n",
    "> ■​ Predicting whether a person has a disease based on **age, blood**\n",
    "> **pressure, cholesterol level** (all continuous values).​\n",
    ">\n",
    "> **2. Multinomial Naïve Bayes**  \n",
    "> ●​ **Assumption**: Features are **discrete counts** (non-negative\n",
    "> integers).​\n",
    ">\n",
    "> ●​ **How it works**: Computes probabilities of counts of features\n",
    "> (e.g., word frequencies).​●​ **When to use**:​  \n",
    "> ○​ When your features represent **count data**.​  \n",
    "> ○​ Common in **Natural Language Processing (NLP)** tasks.​  \n",
    "> ○​ Example:​  \n",
    "> ■​ Text classification → spam filtering, topic categorization.​  \n",
    "> ■​ Features: number of times words like *“free”*, *“win”*, *“offer”*\n",
    "> appear in an email.​\n",
    ">\n",
    "> **3. Bernoulli Naïve Bayes**  \n",
    "> ●​ **Assumption**: Features are **binary (0 or 1)** → whether a feature\n",
    "> is present or not.​ ●​ **How it works**: Models features as **yes/no\n",
    "> (true/false)** indicators instead of counts.​ ●​ **When to use**:​  \n",
    "> ○​ When your features are **binary values**.​  \n",
    "> ○​ Example:​  \n",
    "> ■​ Text classification where features are:​  \n",
    "> ■​ 1 if the word *“free”* appears in the email,​  \n",
    "> ■​ 0 if it doesn’t.​  \n",
    "> ■​ Useful when only the **presence/absence of a word** matters, not the\n",
    "> count.\n",
    ">\n",
    "> Dataset Info:  \n",
    "> ● You can use any suitable datasets like Iris, Breast Cancer, or Wine\n",
    "> from sklearn.datasets or a CSV file you have.\n",
    ">\n",
    "> Question 6: Write a Python program to:  \n",
    "> ● Load the Iris dataset\n",
    ">\n",
    "> ● Train an SVM Classifier with a linear kernel  \n",
    "> ● Print the model's accuracy and support vectors.\n",
    ">\n",
    "> ANS 6 ➖  \n",
    "> from sklearn import datasets  \n",
    "> from sklearn.model_selection import train_test_split  \n",
    "> from sklearn.svm import SVC  \n",
    "> from sklearn.metrics import accuracy_score\n",
    ">\n",
    "> \\# Load the Iris dataset  \n",
    "> iris = datasets.load_iris()  \n",
    "> X, y = iris.data, iris.target\n",
    ">\n",
    "> \\# Split dataset into training and testing sets (80% train, 20% test)\n",
    "> X_train, X_test, y_train, y_test = train_test_split(  \n",
    "> X, y, test_size=0.2, random_state=42, stratify=y  \n",
    "> )\n",
    ">\n",
    "> \\# Train an SVM classifier with a linear kernel  \n",
    "> svm_clf = SVC(kernel='linear', random_state=42)  \n",
    "> svm_clf.fit(X_train, y_train)\n",
    ">\n",
    "> \\# Make predictions  \n",
    "> y_pred = svm_clf.predict(X_test)\n",
    ">\n",
    "> \\# Calculate accuracy  \n",
    "> accuracy = accuracy_score(y_test, y_pred)\n",
    ">\n",
    "> \\# Get support vectors  \n",
    "> support_vectors = svm_clf.support_vectors\\_\n",
    ">\n",
    "> \\# Output results  \n",
    "> print(\"Model Accuracy:\", accuracy)  \n",
    "> print(\"Number of Support Vectors:\", len(support_vectors))  \n",
    "> print(\"Support Vectors (first 5 shown):\\n\", support_vectors\\[:5\\])\n",
    ">\n",
    "> **Output (from execution)**\n",
    ">\n",
    "> ●​ **Model Accuracy:**1.0 (100%)​\n",
    ">\n",
    "> ●​ **Number of Support Vectors:** 26​\n",
    ">\n",
    "> ●​ **Example Support Vectors (first 5):**\n",
    ">\n",
    "> \\[\\[4.5 2.3 1.3 0.3\\]  \n",
    "> \\[4.8 3.4 1.9 0.2\\]  \n",
    "> \\[5.1 3.3 1.7 0.5\\]  \n",
    "> \\[6.8 2.8 4.8 1.4\\]  \n",
    "> \\[6.0 2.9 4.5 1.5\\]\\]\n",
    ">\n",
    "> Question 7: Write a Python program to:  \n",
    "> ● Load the Breast Cancer dataset  \n",
    "> ● Train a Gaussian Naïve Bayes model  \n",
    "> ● Print its classification report including precision, recall, and\n",
    "> F1-score.\n",
    ">\n",
    "> ANS 7 ➖  \n",
    "> from sklearn.datasets import load_breast_cancer  \n",
    "> from sklearn.model_selection import train_test_split  \n",
    "> from sklearn.naive_bayes import GaussianNB  \n",
    "> from sklearn.metrics import classification_report\n",
    ">\n",
    "> \\# Load the Breast Cancer dataset  \n",
    "> cancer = load_breast_cancer()  \n",
    "> X, y = cancer.data, cancer.target\n",
    ">\n",
    "> \\# Split dataset into training and testing sets (80% train, 20% test)\n",
    "> X_train, X_test, y_train, y_test = train_test_split(  \n",
    "> X, y, test_size=0.2, random_state=42, stratify=y  \n",
    "> )\n",
    ">\n",
    "> \\# Train a Gaussian Naive Bayes model  \n",
    "> gnb = GaussianNB()  \n",
    "> gnb.fit(X_train, y_train)\n",
    ">\n",
    "> \\# Make predictions  \n",
    "> y_pred = gnb.predict(X_test)\n",
    ">\n",
    "> \\# Generate classification report  \n",
    "> report = classification_report(y_test, y_pred,\n",
    "> target_names=cancer.target_names) print(\"Classification Report:\\n\")  \n",
    "> print(report)\n",
    ">\n",
    "> Output (from execution)  \n",
    "> precision recall f1-score support\n",
    ">\n",
    "> malignant 0.93 0.90 0.92 42  \n",
    "> benign 0.95 0.96 0.95 72\n",
    ">\n",
    "> accuracy 0.94 114\n",
    ">\n",
    "> macro avg 0.94 0.93 0.93 114  \n",
    "> weighted avg 0.94 0.94 0.94 114\n",
    ">\n",
    "> Question 8: Write a Python program to:  \n",
    "> ● Train an SVM Classifier on the Wine dataset using GridSearchCV to\n",
    "> find the best C and gamma.\n",
    ">\n",
    "> ● Print the best hyperparameters and accuracy  \n",
    "> ANS 8 :-  \n",
    "> from sklearn.datasets import load_wine  \n",
    "> from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "> from sklearn.svm import SVC  \n",
    "> from sklearn.metrics import accuracy_score\n",
    ">\n",
    "> \\# Load the Wine dataset  \n",
    "> wine = load_wine()  \n",
    "> X, y = wine.data, wine.target\n",
    ">\n",
    "> \\# Split dataset into training and testing sets (80% train, 20% test)\n",
    "> X_train, X_test, y_train, y_test = train_test_split(  \n",
    "> X, y, test_size=0.2, random_state=42, stratify=y  \n",
    "> )\n",
    ">\n",
    "> \\# Define parameter grid for GridSearchCV  \n",
    "> param_grid = {  \n",
    "> 'C': \\[0.1, 1, 10, 100\\],  \n",
    "> 'gamma': \\[0.001, 0.01, 0.1, 1\\],  \n",
    "> 'kernel': \\['rbf'\\]  \n",
    "> }\n",
    ">\n",
    "> \\# Initialize SVM classifier  \n",
    "> svm = SVC()\n",
    ">\n",
    "> \\# Grid search with cross-validation  \n",
    "> grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy')\n",
    "> grid_search.fit(X_train, y_train)\n",
    ">\n",
    "> \\# Best hyperparameters  \n",
    "> best_params = grid_search.best_params\\_\n",
    ">\n",
    "> \\# Evaluate on test set  \n",
    "> best_model = grid_search.best_estimator\\_  \n",
    "> y_pred = best_model.predict(X_test)  \n",
    "> accuracy = accuracy_score(y_test, y_pred)\n",
    ">\n",
    "> print(\"Best Hyperparameters:\", best_params)  \n",
    "> print(\"Test Set Accuracy:\", accuracy)\n",
    ">\n",
    "> **Output (from execution)**\n",
    ">\n",
    "> ●​ **Best Hyperparameters:**\n",
    ">\n",
    "> {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    ">\n",
    "> ●​ Test Set Accuracy:  \n",
    "> 0.78 (≈ 77.8%)\n",
    ">\n",
    "> **Interpretation:**\n",
    ">\n",
    "> ●​ The best model used **C = 10** and **gamma = 0.001** with the **RBF\n",
    "> kernel**.​\n",
    ">\n",
    "> ●​ Accuracy on the test set was around **78%**, which is decent but\n",
    "> might improve with feature scaling or a larger parameter grid.\n",
    ">\n",
    "> Question 9: Write a Python program to:  \n",
    "> ● Train a Naïve Bayes Classifier on a synthetic text dataset (e.g.\n",
    "> using sklearn.datasets.fetch_20newsgroups).\n",
    ">\n",
    "> ● Print the model's ROC-AUC score for its predictions.\n",
    ">\n",
    "> ANS 9 :-  \n",
    "> from sklearn.datasets import fetch_20newsgroups  \n",
    "> from sklearn.feature_extraction.text import TfidfVectorizer  \n",
    "> from sklearn.model_selection import train_test_split  \n",
    "> from sklearn.naive_bayes import MultinomialNB  \n",
    "> from sklearn.metrics import roc_auc_score  \n",
    "> from sklearn.preprocessing import label_binarize\n",
    ">\n",
    "> \\# Load a subset of the 20 Newsgroups dataset (for speed)  \n",
    "> categories = \\['sci.space', 'rec.autos', 'comp.graphics'\\]  \n",
    "> newsgroups = fetch_20newsgroups(subset='all',  \n",
    "> categories=categories,  \n",
    "> remove=('headers', 'footers', 'quotes'))\n",
    ">\n",
    "> X, y = newsgroups.data, newsgroups.target\n",
    ">\n",
    "> \\# Convert text to TF-IDF features  \n",
    "> vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "> X_tfidf = vectorizer.fit_transform(X)\n",
    ">\n",
    "> \\# Split into train and test sets\n",
    ">\n",
    "> X_train, X_test, y_train, y_test = train_test_split(  \n",
    "> X_tfidf, y, test_size=0.2, random_state=42, stratify=y  \n",
    "> )\n",
    ">\n",
    "> \\# Train a Multinomial Naive Bayes classifier  \n",
    "> nb_clf = MultinomialNB()  \n",
    "> nb_clf.fit(X_train, y_train)\n",
    ">\n",
    "> \\# Predict probabilities  \n",
    "> y_proba = nb_clf.predict_proba(X_test)\n",
    ">\n",
    "> \\# Binarize the labels (needed for multi-class ROC-AUC)  \n",
    "> y_test_binarized = label_binarize(y_test, classes=\\[0, 1, 2\\])\n",
    ">\n",
    "> \\# Compute ROC-AUC (One-vs-Rest, macro average)  \n",
    "> roc_auc = roc_auc_score(y_test_binarized, y_proba,  \n",
    "> average=\"macro\", multi_class=\"ovr\")\n",
    ">\n",
    "> print(\"ROC-AUC Score:\", roc_auc)\n",
    ">\n",
    "> **What this does:**\n",
    ">\n",
    "> ●​ Loads a **synthetic text dataset** (20newsgroups with 3 categories).​\n",
    ">\n",
    "> ●​ Uses **TF-IDF** to turn text into numeric features.​\n",
    ">\n",
    "> ●​ Trains a **Multinomial Naïve Bayes** (best suited for text\n",
    "> classification).​\n",
    ">\n",
    "> ●​ Evaluates with **ROC-AUC (macro average, one-vs-rest approach)**.\n",
    ">\n",
    "> Question 10: Imagine you’re working as a data scientist for a company\n",
    "> that handles email communications. Your task is to automatically\n",
    "> classify emails as Spam or Not Spam. The emails may contain:  \n",
    "> ● Text with diverse vocabulary  \n",
    "> ● Potential class imbalance (far more legitimate emails than spam)  \n",
    "> ● Some incomplete or missing data Explain the approach you would take\n",
    "> to:  \n",
    "> ● Preprocess the data (e.g. text vectorization, handling missing\n",
    "> data)  \n",
    "> ● Choose and justify an appropriate model (SVM vs. Naïve Bayes)  \n",
    "> ● Address class imbalance  \n",
    "> ● Evaluate the performance of your solution with suitable metrics And\n",
    "> explain the business impact of your solution.\n",
    ">\n",
    "> ANS 10 :-\n",
    ">\n",
    "> **1. Preprocessing the Data**  \n",
    "> ●​ **Handling Missing Data**:​  \n",
    "> ○​ If an email has missing subject or body → replace with \" \" (empty\n",
    "> string).​ ○​ Drop rows with no meaningful text at all.​  \n",
    "> ●​ **Text Cleaning**:​  \n",
    "> ○​ Lowercasing​  \n",
    "> ○​ Removing punctuation, numbers, special characters​  \n",
    "> ○​ Removing stopwords (e.g., “the”, “and”)​  \n",
    "> ○​ Lemmatization/Stemming (reduce words like *running* → *run*).​  \n",
    "> ●​ **Feature Engineering (Text Vectorization)**:​  \n",
    "> ○​ Use **TF-IDF Vectorizer** (preferred over simple Bag of Words since\n",
    "> it downweights common words).​  \n",
    "> ○​ Limit vocabulary size (e.g., top 5,000–10,000 words).​  \n",
    "> ○​ Optionally add extra features:​  \n",
    "> ■​ Email length​  \n",
    "> ■​ Number of links/attachments​  \n",
    "> ■​ Presence of suspicious keywords (“win”, “offer”, “free”).​\n",
    ">\n",
    "> **2. Choosing the Model**  \n",
    "> ●​ **Naïve Bayes**:​  \n",
    "> ○​ Pros: Fast, memory efficient, works well on text classification.​ ○​\n",
    "> Cons: Assumes independence between words (naïve assumption).​ ●​ **SVM\n",
    "> (with Linear Kernel)**:​\n",
    ">\n",
    "> ○​ Pros: Excellent for high-dimensional sparse data (like text), strong\n",
    "> generalization.​○​ Cons: Slower to train on very large datasets.​\n",
    ">\n",
    "> **Choice**: Start with **Multinomial Naïve Bayes** for speed and\n",
    "> simplicity, then benchmark against **Linear SVM**.\n",
    ">\n",
    "> ●​ In practice, **Linear SVM often outperforms NB** for spam detection\n",
    "> when text is long and diverse.\n",
    ">\n",
    "> **3. Handling Class Imbalance**  \n",
    "> ●​ Since spam is often a minority class:​  \n",
    "> ○​ **Resampling methods**:​  \n",
    "> ■​ **Oversample spam** (SMOTE or random oversampling).​  \n",
    "> ■​ **Undersample ham** (careful to not lose too much info).​  \n",
    "> ○​ **Class weights**:​  \n",
    "> ■​ In SVM, set class_weight=\"balanced\".​  \n",
    "> ■​ In Naïve Bayes, adjust priors.​  \n",
    "> ○​ **Threshold tuning**: Adjust decision threshold to favor spam\n",
    "> detection (improve recall).​\n",
    ">\n",
    "> **4. Model Evaluation**  \n",
    "> Since dataset is imbalanced, **accuracy alone is misleading**.​  \n",
    "> Use:  \n",
    "> ●​ **Precision** → Of predicted spam, how many are truly spam?​  \n",
    "> ●​ **Recall (Sensitivity)** → Of actual spam, how many did we catch?\n",
    "> (important, we don’t want spam slipping into inbox).​  \n",
    "> ●​ **F1-score** → Balance between precision & recall.​\n",
    ">\n",
    "> ●​ **ROC-AUC / PR-AUC** → Measures separation power, especially useful\n",
    "> in imbalanced cases.​  \n",
    "> ●​ **Confusion Matrix** → To see misclassifications.​\n",
    ">\n",
    "> **5. Business Impact**  \n",
    "> ●​ **Reduced risk of phishing & scams** → Protects customers.​  \n",
    "> ●​ **Increased user trust** → Better customer satisfaction.​  \n",
    "> ●​ **Operational efficiency** → Less time wasted on spam.​  \n",
    "> ●​ **Scalability** → Automated system saves cost compared to manual\n",
    "> filtering.​\n",
    ">\n",
    "> **Final Summary**:  \n",
    "> ●​ Preprocess with **TF-IDF + cleaning**.​  \n",
    "> ●​ Start with **Naïve Bayes** (fast baseline), benchmark with **Linear\n",
    "> SVM** (likely better).​●​ Handle imbalance with **resampling or class\n",
    "> weights**.​  \n",
    "> ●​ Evaluate using **precision, recall, F1, ROC-AUC**.​  \n",
    "> ●​ Business value: **protects users, builds trust, saves cost**.\n",
    ">\n",
    "> import pandas as pd  \n",
    "> from sklearn.model_selection import train_test_split  \n",
    "> from sklearn.feature_extraction.text import TfidfVectorizer  \n",
    "> from sklearn.naive_bayes import MultinomialNB  \n",
    "> from sklearn.svm import LinearSVC  \n",
    "> from sklearn.metrics import classification_report, roc_auc_score  \n",
    "> from sklearn.preprocessing import label_binarize  \n",
    "> \\# Load SMS Spam dataset (very similar to email spam filtering)  \n",
    "> url =\n",
    "> \"https://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/sms.tsv\"\n",
    "> df = pd.read_csv(url, sep=\"\\t\", header=None, names=\\[\"label\",\n",
    "> \"message\"\\])\n",
    ">\n",
    "> \\# Handle missing values  \n",
    "> df\\[\"message\"\\] = df\\[\"message\"\\].fillna(\"\")\n",
    ">\n",
    "> \\# Encode labels (ham=0, spam=1)  \n",
    "> df\\[\"label\"\\] = df\\[\"label\"\\].map({\"ham\": 0, \"spam\": 1})\n",
    ">\n",
    "> X = df\\[\"message\"\\]  \n",
    "> y = df\\[\"label\"\\]\n",
    ">\n",
    "> \\# Train-test split  \n",
    "> X_train, X_test, y_train, y_test = train_test_split(  \n",
    "> X, y, test_size=0.2, random_state=42, stratify=y  \n",
    "> )\n",
    ">\n",
    "> \\# Vectorize text using TF-IDF  \n",
    "> vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=5000)\n",
    "> X_train_tfidf = vectorizer.fit_transform(X_train)  \n",
    "> X_test_tfidf = vectorizer.transform(X_test)\n",
    ">\n",
    "> \\# --- Model 1: Multinomial Naive Bayes ---  \n",
    "> nb_model = MultinomialNB()  \n",
    "> nb_model.fit(X_train_tfidf, y_train)  \n",
    "> y_pred_nb = nb_model.predict(X_test_tfidf)  \n",
    "> print(\"Naive Bayes Classification Report:\\n\",\n",
    "> classification_report(y_test, y_pred_nb))\n",
    ">\n",
    "> \\# --- Model 2: Linear SVM (with class balance) ---  \n",
    "> svm_model = LinearSVC(class_weight=\"balanced\", random_state=42)  \n",
    "> svm_model.fit(X_train_tfidf, y_train)  \n",
    "> y_pred_svm = svm_model.predict(X_test_tfidf)  \n",
    "> print(\"Linear SVM Classification Report:\\n\",\n",
    "> classification_report(y_test, y_pred_svm))\n",
    ">\n",
    "> \\# ROC-AUC (only valid for probabilistic models like NB, not LinearSVC\n",
    "> directly) y_proba_nb = nb_model.predict_proba(X_test_tfidf)\\[:,1\\]  \n",
    "> roc_auc_nb = roc_auc_score(y_test, y_proba_nb)  \n",
    "> print(\"Naive Bayes ROC-AUC Score:\", roc_auc_nb)\n",
    ">\n",
    "> Output (when run in Python)  \n",
    "> Naive Bayes Classification Report:  \n",
    "> precision recall f1-score support\n",
    ">\n",
    "> 0 0.97 0.98 0.97 965  \n",
    "> 1 0.91 0.87 0.89 150\n",
    ">\n",
    "> accuracy 0.96 1115\n",
    ">\n",
    "> macro avg 0.94 0.93 0.93 1115  \n",
    "> weighted avg 0.96 0.96 0.96 1115  \n",
    "> Linear SVM Classification Report:  \n",
    "> precision recall f1-score support  \n",
    "> 0 0.98 0.99 0.98 965  \n",
    "> 1 0.94 0.90 0.92 150  \n",
    "> accuracy 0.97 1115  \n",
    "> macro avg 0.96 0.95 0.95 1115  \n",
    "> weighted avg 0.97 0.97 0.97 1115  \n",
    "> Naive Bayes ROC-AUC Score: 0.98\n",
    ">\n",
    "> **Interpretation**  \n",
    "> ●​ **Naïve Bayes**: Fast, good performance (\\~96% accuracy, ROC-AUC ≈\n",
    "> 0.98).​●​ **Linear SVM**: Slightly better F1-score on spam detection\n",
    "> (\\~97% accuracy).​●​ Both models work well, but **SVM catches spam\n",
    "> slightly better**.\n",
    ">\n",
    "> **Business Value**:  \n",
    "> ●​ Filters out spam automatically → protects users from scams.​●​\n",
    "> Improves trust and reduces risks.​  \n",
    "> ●​ Scalable to millions of emails with minimal human effort."
   ],
   "id": "42a14256-91c8-446e-92a7-ab6bf11055d3"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
