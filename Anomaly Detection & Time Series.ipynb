{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question 1:** What is Anomaly Detection? Explain its types (point,\n",
    "> contextual, and collective anomalies) with examples.\n",
    ">\n",
    "> **Answer 1 :-**  \n",
    "> **Anomaly detection** is the process of identifying unusual patterns,\n",
    "> events, or observations in data that do not follow the expected\n",
    "> behavior.\n",
    ">\n",
    "> These unusual observations are called **anomalies** (or outliers).\n",
    ">\n",
    "> In real life, anomalies often indicate something important, like:\n",
    ">\n",
    "> ‚óè‚Äã Fraudulent transactions in banking‚Äã\n",
    ">\n",
    "> ‚óè‚Äã Faulty sensors in manufacturing‚Äã\n",
    ">\n",
    "> ‚óè‚Äã Sudden spikes in website traffic‚Äã\n",
    ">\n",
    "> ‚óè‚Äã Rare diseases in healthcare\n",
    ">\n",
    "> **Types of Anomalies**\n",
    ">\n",
    "> **1. Point Anomalies**\n",
    ">\n",
    "> ‚óè‚Äã A **single data point** is very different from the rest of the data.‚Äã\n",
    ">\n",
    "> ‚óè‚Äã Most common type of anomaly.‚Äã\n",
    ">\n",
    "> **Example:**\n",
    ">\n",
    "> ‚óè‚Äã In a dataset of monthly credit card transactions where most users\n",
    "> spend between ‚Çπ5,000‚Äì‚Çπ20,000, a transaction of **‚Çπ2,00,000** would be\n",
    "> a point anomaly.‚Äã\n",
    ">\n",
    "> ‚óè‚Äã A sensor in a machine showing a sudden temperature of **200¬∞C** when\n",
    "> normal readings are around 30‚Äì40¬∞C.\n",
    ">\n",
    "> **2. Contextual Anomalies**\n",
    ">\n",
    "> ‚óè‚Äã A data point is unusual **only in a specific context** (depends on\n",
    "> time, location, or situation).‚Äã\n",
    ">\n",
    "> ‚óè‚Äã Common in **time-series data**.‚Äã\n",
    ">\n",
    "> **Example:**\n",
    ">\n",
    "> ‚óè‚Äã A temperature of **30¬∞C** is normal in summer but abnormal in winter\n",
    "> in Delhi.‚Äã\n",
    ">\n",
    "> ‚óè‚Äã An employee logging in at **3:00 AM** might be unusual (context:\n",
    "> working hours), but normal for a night-shift worker.\n",
    ">\n",
    "> **3. Collective Anomalies**\n",
    ">\n",
    "> ‚óè‚Äã A **group of data points together** form an anomaly, even though\n",
    "> individual points may look normal.‚Äã\n",
    ">\n",
    "> ‚óè‚Äã Often indicate **sequential or group-based unusual behavior**.‚Äã\n",
    ">\n",
    "> **Example:**\n",
    ">\n",
    "> ‚óè‚Äã In network traffic monitoring, a **sudden burst of packets over 10\n",
    "> minutes** may indicate a **DDoS attack**.‚Äã\n",
    ">\n",
    "> ‚óè‚Äã In stock market data, a series of small but consistent drops in\n",
    "> stock price could indicate insider trading.‚Äã\n",
    ">\n",
    "> **Question 2:** Compare Isolation Forest, DBSCAN, and Local Outlier\n",
    "> Factor in terms of their approach and suitable use cases.\n",
    ">\n",
    "> **Answer 2 :-**\n",
    ">\n",
    "> **Comparison of Isolation Forest, DBSCAN,**\n",
    ">\n",
    "> **and Local Outlier Factor**\n",
    ">\n",
    "> **1. Isolation Forest (IF)**\n",
    ">\n",
    "> ‚óè‚Äã **Approach:‚Äã**\n",
    ">\n",
    "> ‚óã‚Äã Based on the principle that anomalies are **easier to isolate** than\n",
    "> normal points.‚Äã\n",
    ">\n",
    "> ‚óã‚Äã Builds random decision trees; anomalies end up in shorter paths\n",
    "> because they are rare and distinct.‚Äã  \n",
    "> ‚óè‚Äã **Type:** Ensemble method (tree-based).‚Äã  \n",
    "> ‚óè‚Äã **Use Cases:‚Äã**  \n",
    "> ‚óã‚Äã Large, high-dimensional datasets.‚Äã  \n",
    "> ‚óã‚Äã Fraud detection (credit card, banking).‚Äã  \n",
    "> ‚óã‚Äã Intrusion detection in cybersecurity.‚Äã  \n",
    "> ‚óè‚Äã **Strengths:‚Äã**  \n",
    "> ‚óã‚Äã Scales well to big data.‚Äã  \n",
    "> ‚óã‚Äã Works without distance calculation (better in high dimensions).‚Äã  \n",
    "> ‚óè‚Äã **Limitations:‚Äã**  \n",
    "> ‚óã‚Äã Assumes anomalies are few and different in distribution.‚Äã  \n",
    "> ‚óã‚Äã Not good for finding **clusters of anomalies**.‚Äã\n",
    ">\n",
    "> **2. DBSCAN (Density-Based Spatial Clustering of Applications with\n",
    "> Noise)** ‚óè‚Äã **Approach:‚Äã**  \n",
    "> ‚óã‚Äã Groups together points that are close (high density).‚Äã  \n",
    "> ‚óã‚Äã Points in low-density regions are considered anomalies (noise).‚Äã ‚óè‚Äã\n",
    "> **Type:** Density-based clustering.‚Äã  \n",
    "> ‚óè‚Äã **Use Cases:‚Äã**\n",
    ">\n",
    "> ‚óã‚Äã Spatial/geographical data (e.g., detecting outlier GPS locations).‚Äã  \n",
    "> ‚óã‚Äã Clustering + anomaly detection simultaneously.‚Äã  \n",
    "> ‚óã‚Äã Irregularly shaped clusters.‚Äã  \n",
    "> ‚óè‚Äã **Strengths:‚Äã**  \n",
    "> ‚óã‚Äã Finds both clusters and anomalies.‚Äã  \n",
    "> ‚óã‚Äã No need to specify number of clusters (unlike K-Means).‚Äã  \n",
    "> ‚óè‚Äã **Limitations:‚Äã**  \n",
    "> ‚óã‚Äã Struggles with high-dimensional data.‚Äã  \n",
    "> ‚óã‚Äã Sensitive to parameters **Œµ (neighborhood radius)** and **MinPts\n",
    "> (minimum** **points in a cluster)**.‚Äã\n",
    ">\n",
    "> **3. Local Outlier Factor (LOF)**  \n",
    "> ‚óè‚Äã **Approach:‚Äã**  \n",
    "> ‚óã‚Äã Compares the **local density** of a point with that of its\n",
    "> neighbors.‚Äã ‚óã‚Äã If a point has much lower density than neighbors ‚Üí it‚Äôs\n",
    "> an anomaly.‚Äã ‚óè‚Äã **Type:** Density-based local anomaly detection.‚Äã  \n",
    "> ‚óè‚Äã **Use Cases:‚Äã**  \n",
    "> ‚óã‚Äã Detecting local anomalies where data is not globally uniform.‚Äã ‚óã‚Äã\n",
    "> Fraud detection when some regions are denser than others.‚Äã ‚óã‚Äã\n",
    "> Medical/biological data where clusters have varying densities.‚Äã\n",
    ">\n",
    "> ‚óè‚Äã **Strengths:‚Äã**\n",
    ">\n",
    "> ‚óã‚Äã Works well for datasets with varying density.‚Äã\n",
    ">\n",
    "> ‚óã‚Äã Detects **contextual anomalies**.‚Äã\n",
    ">\n",
    "> ‚óè‚Äã **Limitations:‚Äã**\n",
    ">\n",
    "> ‚óã‚Äã Computationally expensive for large datasets.‚Äã\n",
    ">\n",
    "> ‚óã‚Äã Sensitive to parameter **k (number of neighbors)**.‚Äã\n",
    ">\n",
    "> **Question 3:** What are the key components of a Time Series? Explain\n",
    "> each with one example.\n",
    ">\n",
    "> **Answer 3 :-**\n",
    ">\n",
    "> **Key Components of a Time Series**\n",
    ">\n",
    "> A **time series** is a sequence of data points collected or recorded\n",
    "> at specific time intervals (daily, monthly, yearly, etc.).‚Äã  \n",
    "> It usually has **four main components**:\n",
    ">\n",
    "> **1. Trend (T)**\n",
    ">\n",
    "> ‚óè‚Äã The **long-term direction** of the data (upward, downward, or\n",
    "> stable) over a long period.‚Äã\n",
    ">\n",
    "> ‚óè‚Äã Shows the overall growth or decline.‚Äã\n",
    ">\n",
    "> **Example:**\n",
    ">\n",
    "> ‚óè‚Äã The number of internet users in India has been **increasing\n",
    "> steadily** over the last 20 years.‚Äã\n",
    ">\n",
    "> ‚óè‚Äã Stock market index (like NIFTY 50) shows a long-term upward trend\n",
    "> despite short-term fluctuations.‚Äã\n",
    ">\n",
    "> **2. Seasonality (S)**  \n",
    "> ‚óè‚Äã **Regular, repeating patterns** in data that occur at fixed\n",
    "> intervals (daily, weekly, monthly, yearly).‚Äã  \n",
    "> ‚óè‚Äã Caused by seasonal factors such as weather, festivals, holidays,\n",
    "> etc.‚Äã\n",
    ">\n",
    "> **Example:**  \n",
    "> ‚óè‚Äã Ice cream sales **increase every summer** and drop in winter.‚Äã‚óè‚Äã\n",
    "> E-commerce sales **spike during Diwali and Christmas seasons**.‚Äã\n",
    ">\n",
    "> **3. Cyclic Component (C)**  \n",
    "> ‚óè‚Äã **Long-term oscillations** in data that are not strictly periodic\n",
    "> (unlike seasonality).‚Äã‚óè‚Äã Often linked to **business cycles or economic\n",
    "> trends**.‚Äã  \n",
    "> ‚óè‚Äã Duration is more than a year and not fixed.‚Äã\n",
    ">\n",
    "> **Example:**  \n",
    "> ‚óè‚Äã Economic cycles of **boom ‚Üí recession ‚Üí recovery** affect\n",
    "> unemployment rates.‚Äã‚óè‚Äã Real estate prices going up and down over decades\n",
    "> due to market cycles.‚Äã\n",
    ">\n",
    "> **4. Irregular/Random Component (I)**  \n",
    "> ‚óè‚Äã Unpredictable, random variations in data due to **unexpected\n",
    "> events**.‚Äã‚óè‚Äã Cannot be explained by trend, seasonality, or cycles.‚Äã\n",
    ">\n",
    "> **Example:**\n",
    ">\n",
    "> ‚óè‚Äã Sudden drop in airline travel due to **COVID-19 pandemic**.‚Äã\n",
    ">\n",
    "> ‚óè‚Äã A natural disaster causing unusual spikes in demand for certain\n",
    "> goods.\n",
    ">\n",
    "> **Question 4:** Define Stationary in time series. How can you test and\n",
    "> transform a non-stationary series into a stationary one?\n",
    ">\n",
    "> **Answer 4 :-**\n",
    ">\n",
    "> A **stationary time series** is one whose **statistical properties**\n",
    "> (like mean, variance, and autocorrelation) do not change over time.‚Äã  \n",
    "> In simple words ‚Üí the series looks \"similar\" throughout, without\n",
    "> long-term trends or changing variance.\n",
    ">\n",
    "> Stationarity is important because many time series forecasting models\n",
    "> (like ARIMA) assume the data is stationary.\n",
    ">\n",
    "> **Types of Stationarity**\n",
    ">\n",
    "> 1.‚Äã **Strict Stationarity** ‚Äì The complete probability distribution\n",
    "> remains constant over time. (Rare in practice)‚Äã\n",
    ">\n",
    "> 2.‚Äã **Weak Stationarity** ‚Äì Only the first two moments (mean and\n",
    "> variance) are constant, and autocovariance depends only on the lag,\n",
    "> not time. (Most commonly tested)\n",
    ">\n",
    "> **How to Test Stationarity**\n",
    ">\n",
    "> **1. Visual Inspection**\n",
    ">\n",
    "> ‚óè‚Äã Plot the time series.‚Äã\n",
    ">\n",
    "> ‚óè‚Äã If it shows a clear **trend, seasonality, or changing variance**,\n",
    "> it‚Äôs likely **non-stationary**.‚Äã\n",
    ">\n",
    "> üìå Example: Sales data increasing over years ‚Üí non-stationary.\n",
    ">\n",
    "> **2. Summary Statistics**\n",
    ">\n",
    "> ‚óè‚Äã Split data into two halves and compare **mean and variance**.‚Äã\n",
    ">\n",
    "> ‚óè‚Äã If they differ significantly ‚Üí non-stationary.‚Äã\n",
    ">\n",
    "> **3. Statistical Tests**  \n",
    "> ‚óè‚Äã **Augmented Dickey-Fuller (ADF) Test‚Äã**  \n",
    "> ‚óã‚Äã Null Hypothesis (H0): Series has a unit root (non-stationary).‚Äã ‚óã‚Äã\n",
    "> Alternative (H1): Series is stationary.‚Äã  \n",
    "> ‚óè‚Äã **KPSS Test (Kwiatkowski-Phillips-Schmidt-Shin)‚Äã**  \n",
    "> ‚óã‚Äã Null Hypothesis (H0): Series is stationary.‚Äã  \n",
    "> ‚óã‚Äã Alternative (H1): Series is non-stationary.‚Äã\n",
    ">\n",
    "> üëâ Often, both tests are used together for confirmation.\n",
    ">\n",
    "> üîπ **How to Transform a Non-Stationary Series into Stationary**  \n",
    "> If the series is non-stationary, we can apply transformations:  \n",
    "> **1. Differencing**  \n",
    "> ‚óè‚Äã Subtract current value from previous value:‚Äã\n",
    "\n",
    "<table style=\"width:100%;\">\n",
    "<colgroup>\n",
    "<col style=\"width: 16%\" />\n",
    "<col style=\"width: 16%\" />\n",
    "<col style=\"width: 16%\" />\n",
    "<col style=\"width: 16%\" />\n",
    "<col style=\"width: 16%\" />\n",
    "<col style=\"width: 16%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th>‚Äã</th>\n",
    "<th>‚Äã</th>\n",
    "<th>‚Äã</th>\n",
    "<th>‚Äã</th>\n",
    "<th>‚Äã</th>\n",
    "<th><blockquote>\n",
    "<p>Yt‚Ä≤‚Äã=Yt‚Äã‚àíYt‚àí1‚Äã</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "> ‚óè‚Äã Removes trend/seasonality.‚Äã  \n",
    "> Example: Stock prices ‚Üí take difference to stabilize.‚Äã\n",
    ">\n",
    "> **2. Log Transformation**\n",
    ">\n",
    "> ‚óè‚Äã Apply log to reduce **variance fluctuations**.‚Äã  \n",
    "> Example: Sales data with exponential growth ‚Üí apply log to compress\n",
    "> large values.‚Äã\n",
    ">\n",
    "> **3. Seasonal Differencing**\n",
    ">\n",
    "> ‚óè‚Äã Subtract value from its seasonal lag:‚Äã\n",
    "\n",
    "<table style=\"width:100%;\">\n",
    "<colgroup>\n",
    "<col style=\"width: 16%\" />\n",
    "<col style=\"width: 16%\" />\n",
    "<col style=\"width: 16%\" />\n",
    "<col style=\"width: 16%\" />\n",
    "<col style=\"width: 16%\" />\n",
    "<col style=\"width: 16%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th>‚Äã</th>\n",
    "<th>‚Äã</th>\n",
    "<th>‚Äã</th>\n",
    "<th>‚Äã</th>\n",
    "<th>‚Äã</th>\n",
    "<th><blockquote>\n",
    "<p>Yt‚Ä≤‚Äã=Yt‚Äã‚àíYt‚àím‚Äã</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "> (where m = seasonal period, e.g., 12 for monthly data).\n",
    ">\n",
    "> Example: Monthly electricity consumption (subtract this month‚Äôs value\n",
    "> from last year‚Äôs same month).\n",
    ">\n",
    "> **4. Detrending**\n",
    ">\n",
    "> ‚óè‚Äã Fit a regression line to capture trends and remove them.‚Äã Example:\n",
    "> Remove linear upward trend in GDP data.‚Äã\n",
    ">\n",
    "> **5. Box-Cox Transformation**\n",
    ">\n",
    "> ‚óè‚Äã General power transformation to stabilize variance.‚Äã\n",
    ">\n",
    "> **Question 5:** Differentiate between AR, MA, ARIMA, SARIMA, and\n",
    "> SARIMAX models in terms of structure and application.\n",
    ">\n",
    "> **Answer 5 :-**\n",
    ">\n",
    "> **1. AR (Autoregressive)**\n",
    ">\n",
    "> ‚óè‚Äã Uses past values to predict the future.‚Äã\n",
    ">\n",
    "> ‚óè‚Äã Example: Tomorrow‚Äôs temperature depends on yesterday‚Äôs and today‚Äôs\n",
    "> temperature.‚Äã\n",
    ">\n",
    "> ‚óè‚Äã Good when data depends on its own history.\n",
    ">\n",
    "> **2. MA (Moving Average)**\n",
    ">\n",
    "> ‚óè‚Äã Uses **past errors (shocks)** to predict the future.‚Äã\n",
    ">\n",
    "> ‚óè‚Äã Example: Today‚Äôs sales depend on unexpected events (errors) in the\n",
    "> last few days.‚Äã\n",
    ">\n",
    "> ‚óè‚Äã Good for **short-term noise smoothing**.\n",
    ">\n",
    "> **3. ARIMA (AutoRegressive Integrated Moving Average)**\n",
    ">\n",
    "> ‚óè‚Äã Combines **AR + MA + Differencing**.‚Äã\n",
    ">\n",
    "> ‚óè‚Äã Handles **trend** in data (non-stationary series).‚Äã\n",
    ">\n",
    "> ‚óè‚Äã Example: Forecasting GDP growth, stock prices, sales.\n",
    ">\n",
    "> **5. SARIMAX (Seasonal ARIMA with Exogenous Variables)**\n",
    ">\n",
    "> ‚óè‚Äã SARIMA + **external factors (X)**.‚Äã\n",
    ">\n",
    "> ‚óè‚Äã Uses outside information that affects the series.‚Äã\n",
    ">\n",
    "> ‚óè‚Äã Example: Electricity demand (depends on temperature), sales (depends\n",
    "> on holidays or ads).‚Äã\n",
    ">\n",
    "> **Dataset:**  \n",
    "> **‚óè NYC Taxi Fare Data**  \n",
    "> **‚óè AirPassengers Dataset**  \n",
    "> **Question 6:** Load a time series dataset (e.g., AirPassengers), plot\n",
    "> the original series, and decompose it into trend, seasonality, and\n",
    "> residual components\n",
    ">\n",
    "> **Answer 6 :-**  \n",
    "> \\# Step 1: Import libraries  \n",
    "> import pandas as pd  \n",
    "> import matplotlib.pyplot as plt  \n",
    "> from statsmodels.tsa.seasonal import seasonal_decomposeimport\n",
    "> statsmodels.api as sm\n",
    ">\n",
    "> \\# Step 2: Load the AirPassengers dataset  \n",
    "> \\# (available in statsmodels)  \n",
    "> data = sm.datasets.airpassengers.load_pandas().data\n",
    ">\n",
    "> \\# Convert 'Month' to datetime  \n",
    "> data\\['Month'\\] = pd.to_datetime(data\\['Month'\\])  \n",
    "> data.set_index('Month', inplace=True)\n",
    ">\n",
    "> \\# Step 3: Plot original series  \n",
    "> plt.figure(figsize=(10,5))  \n",
    "> plt.plot(data\\['AirPassengers'\\], label=\"AirPassengers\")  \n",
    "> plt.title(\"AirPassengers Dataset (1949-1960)\")  \n",
    "> plt.xlabel(\"Year\")  \n",
    "> plt.ylabel(\"Number of Passengers\")  \n",
    "> plt.legend()  \n",
    "> plt.show()\n",
    ">\n",
    "> \\# Step 4: Decompose into trend, seasonality, residuals  \n",
    "> decomposition = seasonal_decompose(data\\['AirPassengers'\\],\n",
    "> model='multiplicative',period=12)\n",
    ">\n",
    "> \\# Step 5: Plot decomposition  \n",
    "> decomposition.plot()  \n",
    "> plt.show()\n",
    ">\n",
    "> **What You‚Äôll See in the Output:**\n",
    ">\n",
    "> 1.‚Äã **Original Series** ‚Üí Increasing passengers with strong\n",
    "> seasonality.‚Äã\n",
    ">\n",
    "> 2.‚Äã **Trend** ‚Üí Long-term upward growth in air travel.‚Äã\n",
    ">\n",
    "> 3.‚Äã **Seasonality** ‚Üí Repeating yearly pattern (summer/winter peaks).‚Äã\n",
    ">\n",
    "> 4.‚Äã **Residual** ‚Üí Random fluctuations not explained by\n",
    "> trend/seasonality.\n",
    ">\n",
    "> **Question 7:** Apply Isolation Forest on a numerical dataset (e.g.,\n",
    "> NYC Taxi Fare) to detect anomalies. Visualize the anomalies on a 2D\n",
    "> scatter plot.\n",
    ">\n",
    "> **Answer 7 :-**  \n",
    "> \\# Step 1: Import libraries  \n",
    "> import pandas as pd  \n",
    "> import matplotlib.pyplot as plt  \n",
    "> from sklearn.ensemble import IsolationForest\n",
    ">\n",
    "> \\# Step 2: Load dataset (NYC Taxi Fare)  \n",
    "> \\# Example: If CSV file is available  \n",
    "> \\# data = pd.read_csv(\"nyc_taxi_fare.csv\")\n",
    ">\n",
    "> \\# For demonstration, let's simulate small taxi fare-like datasetdata\n",
    "> = pd.DataFrame({\n",
    "\n",
    "<table>\n",
    "<colgroup>\n",
    "<col style=\"width: 100%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th><blockquote>\n",
    "<p>\"fare_amount\": [5, 8, 7, 6, 15, 7, 6, 300, 10, 9, 7, 5, 400, 8, 6], #\n",
    "Some extreme fares</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "> = anomalies\n",
    "\n",
    "<table>\n",
    "<colgroup>\n",
    "<col style=\"width: 100%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th><blockquote>\n",
    "<p>\"trip_distance\": [1, 2, 1.5, 2, 3, 1.8, 2, 0.5, 2.5, 3, 2.2, 1.7,\n",
    "0.3, 2, 1.6]</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "> })\n",
    ">\n",
    "> \\# Step 3: Apply Isolation Forest  \n",
    "> iso_forest = IsolationForest(contamination=0.1, random_state=42) \\#\n",
    "> contamination \\~expected % of anomalies  \n",
    "> data\\['anomaly'\\] = iso_forest.fit_predict(data\\[\\['fare_amount',\n",
    "> 'trip_distance'\\]\\])\n",
    ">\n",
    "> \\# anomaly = -1 (outlier), 1 (normal)  \n",
    "> outliers = data\\[data\\['anomaly'\\] == -1\\]  \n",
    "> inliers = data\\[data\\['anomaly'\\] == 1\\]\n",
    ">\n",
    "> \\# Step 4: Visualize anomalies  \n",
    "> plt.figure(figsize=(8,6))  \n",
    "> plt.scatter(inliers\\['trip_distance'\\], inliers\\['fare_amount'\\],\n",
    "> c='blue', label='Normal',alpha=0.6)  \n",
    "> plt.scatter(outliers\\['trip_distance'\\], outliers\\['fare_amount'\\],\n",
    "> c='red', label='Anomaly',marker='x', s=100)  \n",
    "> plt.title(\"Isolation Forest - NYC Taxi Fare Anomaly Detection\")  \n",
    "> plt.xlabel(\"Trip Distance (miles)\")  \n",
    "> plt.ylabel(\"Fare Amount (\\$)\")  \n",
    "> plt.legend()  \n",
    "> plt.show()\n",
    ">\n",
    "> **What Happens Here:**\n",
    ">\n",
    "> ‚óè‚Äã **Input Features** ‚Üí fare_amount and trip_distance‚Äã\n",
    ">\n",
    "> ‚óè‚Äã **Isolation Forest** marks unusual points as anomalies (label = -1)‚Äã\n",
    ">\n",
    "> ‚óè‚Äã **Scatter Plot**:‚Äã\n",
    ">\n",
    "> ‚óã‚Äã Blue = normal fares‚Äã\n",
    ">\n",
    "> ‚óã‚Äã Red (X) = anomalies (e.g., super high fares like \\$300 or \\$400 for\n",
    "> a short trip)\n",
    ">\n",
    "> **Expected Output**\n",
    ">\n",
    "> **Scatter Plot**  \n",
    "> ‚óè‚Äã **Blue points** ‚Üí Normal taxi fares (around \\$5‚Äì\\$15 for short\n",
    "> trips).‚Äã\n",
    ">\n",
    "> ‚óè‚Äã **Red X points** ‚Üí Anomalies detected (e.g., fares of **\\$300** and\n",
    "> **\\$400** for short trips).‚Äã\n",
    ">\n",
    "> It would look like this (illustration):  \n",
    "> Fare Amount (\\$)  \n",
    "> ‚Üë  \n",
    "> \\| X (400\\$ anomaly)  \n",
    "> \\| X (300\\$ anomaly)  \n",
    "> \\|  \n",
    "> \\| ‚óè ‚óè ‚óè ‚óè ‚óè  \n",
    "> \\| ‚óè ‚óè ‚óè ‚óè ‚óè  \n",
    "> +--------------------------------‚Üí Trip Distance (miles)\n",
    ">\n",
    "> ‚óè‚Äã Most fares cluster around **(trip distance 1‚Äì3, fare \\$5‚Äì15)**.‚Äã\n",
    ">\n",
    "> ‚óè‚Äã Anomalies (300, 400) are marked **red X** far away from the normal\n",
    "> cluster.‚Äã\n",
    ">\n",
    "> **Question 8:** Train a SARIMA model on the monthly airline passengers\n",
    "> dataset.\n",
    ">\n",
    "> Forecast the next 12 months and visualize the results.\n",
    ">\n",
    "> **Answer 8 :-**  \n",
    "> import pandas as pd  \n",
    "> import matplotlib.pyplot as plt  \n",
    "> import statsmodels.api as sm  \n",
    "> from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    ">\n",
    "> \\# Load built-in AirPassengers dataset  \n",
    "> data = sm.datasets.airpassengers.load_pandas().data\n",
    ">\n",
    "> \\# Convert 'Month' to datetime and set as index  \n",
    "> data\\['Month'\\] = pd.to_datetime(data\\['Month'\\])  \n",
    "> data.set_index('Month', inplace=True)\n",
    ">\n",
    "> \\# Rename column for convenience  \n",
    "> data = data.rename(columns={\"AirPassengers\": \"Passengers\"})\n",
    ">\n",
    "> \\# Fit SARIMA model  \n",
    "> model = SARIMAX(data\\['Passengers'\\], order=(1,1,1),\n",
    "> seasonal_order=(1,1,1,12))results = model.fit(disp=False)  \n",
    "> print(results.summary())\n",
    ">\n",
    "> \\# Forecast for next 12 months\n",
    ">\n",
    "> forecast = results.get_forecast(steps=12)  \n",
    "> forecast_index =\n",
    "> pd.date_range(start=data.index\\[-1\\]+pd.DateOffset(months=1),periods=12,\n",
    "> freq='M')\n",
    ">\n",
    "> \\# Get predicted mean and confidence intervals  \n",
    "> forecast_mean = forecast.predicted_mean  \n",
    "> forecast_ci = forecast.conf_int()\n",
    ">\n",
    "> plt.figure(figsize=(10,6))  \n",
    "> plt.plot(data.index, data\\['Passengers'\\], label=\"Original Data\")  \n",
    "> plt.plot(forecast_index, forecast_mean, label=\"Forecast\",\n",
    "> color='red')plt.fill_between(forecast_index,\n",
    "\n",
    "<table>\n",
    "<colgroup>\n",
    "<col style=\"width: 100%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th><blockquote>\n",
    "<p>forecast_ci.iloc[:, 0],</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "<table>\n",
    "<colgroup>\n",
    "<col style=\"width: 100%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th><blockquote>\n",
    "<p>forecast_ci.iloc[:, 1],</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "<table>\n",
    "<colgroup>\n",
    "<col style=\"width: 100%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th><blockquote>\n",
    "<p>color='pink', alpha=0.3, label=\"Confidence Interval\")</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "> plt.title(\"SARIMA Forecast - AirPassengers Dataset\")  \n",
    "> plt.xlabel(\"Year\")  \n",
    "> plt.ylabel(\"Number of Passengers\")  \n",
    "> plt.legend()  \n",
    "> plt.show()\n",
    ">\n",
    "> **Expected Output**\n",
    ">\n",
    "> The **plot** will show:\n",
    ">\n",
    "> ‚óè‚Äã **Blue line** ‚Üí Original passenger data (1949‚Äì1960).‚Äã\n",
    ">\n",
    "> ‚óè‚Äã **Red line** ‚Üí Forecasted passenger numbers for the next 12 months\n",
    "> (1961).‚Äã\n",
    ">\n",
    "> ‚óè‚Äã **Shaded pink region** ‚Üí Confidence interval (uncertainty in\n",
    "> forecast).\n",
    ">\n",
    "> The forecast continues the **upward trend + seasonality** (higher\n",
    "> values in summer, lower in winter).\n",
    ">\n",
    "> Typical forecasted values (approximate, depending on SARIMA tuning):\n",
    ">\n",
    "> **Question 9**: Apply Local Outlier Factor (LOF) on any numerical\n",
    "> dataset to detect anomalies and visualize them using matplotlib.\n",
    ">\n",
    "> **Answer 9 :-**  \n",
    "> import numpy as np  \n",
    "> import pandas as pd  \n",
    "> import matplotlib.pyplot as plt  \n",
    "> from sklearn.neighbors import LocalOutlierFactor\n",
    ">\n",
    "> \\# Simulated dataset (fare vs. distance)  \n",
    "> data = pd.DataFrame({\n",
    "\n",
    "<table>\n",
    "<colgroup>\n",
    "<col style=\"width: 100%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th><blockquote>\n",
    "<p>\"fare_amount\": [5, 6, 7, 8, 10, 15, 6, 7, 8, 9, 12, 300, 400, 5, 7],\n",
    "# anomalies = 300,</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "> 400\n",
    "\n",
    "<table>\n",
    "<colgroup>\n",
    "<col style=\"width: 100%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th><blockquote>\n",
    "<p>\"trip_distance\": [1, 1.5, 2, 2.2, 2.5, 3, 1.7, 1.8, 2.3, 2.1, 3.2,\n",
    "0.5, 0.3, 1.2, 1.6]</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "> })\n",
    ">\n",
    "> \\# Initialize LOF  \n",
    "> lof = LocalOutlierFactor(n_neighbors=5, contamination=0.1)\n",
    ">\n",
    "> \\# Fit and predict  \n",
    "> data\\['anomaly'\\] = lof.fit_predict(data\\[\\['fare_amount',\n",
    "> 'trip_distance'\\]\\])\n",
    ">\n",
    "> \\# Separate normal and anomalies  \n",
    "> outliers = data\\[data\\['anomaly'\\] == -1\\]  \n",
    "> inliers = data\\[data\\['anomaly'\\] == 1\\]\n",
    ">\n",
    "> plt.figure(figsize=(8,6))  \n",
    "> plt.scatter(inliers\\['trip_distance'\\], inliers\\['fare_amount'\\],\n",
    "\n",
    "<table>\n",
    "<colgroup>\n",
    "<col style=\"width: 100%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th><blockquote>\n",
    "<p>c='blue', label='Normal', alpha=0.6)</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "> plt.scatter(outliers\\['trip_distance'\\], outliers\\['fare_amount'\\],\n",
    "\n",
    "<table>\n",
    "<colgroup>\n",
    "<col style=\"width: 100%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th><blockquote>\n",
    "<p>c='red', label='Anomaly', marker='x', s=100)</p>\n",
    "</blockquote></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "> plt.title(\"Local Outlier Factor (LOF) - Anomaly Detection\")  \n",
    "> plt.xlabel(\"Trip Distance (miles)\")  \n",
    "> plt.ylabel(\"Fare Amount (\\$)\")  \n",
    "> plt.legend()  \n",
    "> plt.show()\n",
    ">\n",
    "> **Expected Output**\n",
    ">\n",
    "> Scatter Plot will show:\n",
    ">\n",
    "> ‚óè‚Äã **Blue points** ‚Üí Normal data (fare \\~ \\$5‚Äì15 for trips 1‚Äì3 miles).‚Äã\n",
    ">\n",
    "> ‚óè‚Äã **Red X points** ‚Üí Anomalies (fares \\$300 & \\$400 at very short\n",
    "> distances).‚Äã\n",
    ">\n",
    "> It would look something like this (conceptual sketch):\n",
    ">\n",
    "> Fare Amount (\\$)  \n",
    "> ‚Üë  \n",
    "> \\| X (400 anomaly)  \n",
    "> \\| X (300 anomaly)  \n",
    "> \\|  \n",
    "> \\| ‚óè ‚óè ‚óè ‚óè ‚óè  \n",
    "> \\| ‚óè ‚óè ‚óè ‚óè  \n",
    "> +--------------------------------‚Üí Trip Distance (miles)\n",
    "\n",
    "**Question 10:** You are working as a data scientist for a power grid\n",
    "monitoring company.\n",
    "\n",
    "> Your goal is to forecast energy demand and also detect abnormal spikes\n",
    "> or drops in real-time consumption data collected every 15 minutes. The\n",
    "> dataset includes features like timestamp, region, weather conditions,\n",
    "> and energy usage. Explain your real-time data science workflow:  \n",
    "> ‚óè How would you detect anomalies in this streaming data (Isolation\n",
    "> Forest / LOF / DBSCAN)?\n",
    ">\n",
    "> ‚óè Which time series model would you use for short-term forecasting\n",
    "> (ARIMA / SARIMA / SARIMAX)?\n",
    ">\n",
    "> ‚óè How would you validate and monitor the performance over time?\n",
    ">\n",
    "> ‚óè How would this solution help business decisions or operations?\n",
    ">\n",
    "> **ANSWER 10 :-**\n",
    ">\n",
    "> **Problem:**\n",
    ">\n",
    "> We have **streaming energy consumption data (15-min intervals)** with\n",
    "> features like **timestamp, region, weather, usage**.‚Äã  \n",
    "> We need to:\n",
    ">\n",
    "> 1.‚Äã Forecast short-term demand.‚Äã\n",
    ">\n",
    "> 2.‚Äã Detect abnormal spikes/drops in real time.‚Äã\n",
    ">\n",
    "> 3.‚Äã Ensure model is validated and monitored continuously.\n",
    ">\n",
    "> **1. Anomaly Detection in Streaming Data**\n",
    ">\n",
    "> ‚óè‚Äã **Choice of Algorithm:‚Äã**\n",
    ">\n",
    "> ‚óã‚Äã **Isolation Forest** ‚Üí scalable, works well in real time, handles\n",
    "> high-dimensional data.‚Äã\n",
    ">\n",
    "> ‚óã‚Äã **LOF (Local Outlier Factor)** ‚Üí detects local/contextual anomalies\n",
    "> (e.g., one region consuming abnormally compared to neighbors).‚Äã\n",
    ">\n",
    "> ‚óã‚Äã **DBSCAN** ‚Üí good for clustering + anomaly detection, but less\n",
    "> suitable for streaming (requires re-fitting).‚Äã\n",
    ">\n",
    "> **Best fit here:Isolation Forest (real-time & scalable)** + optionally\n",
    "> **LOF** for regional contextual anomalies.\n",
    ">\n",
    "> Example: If demand usually ranges 100‚Äì200 MW, and suddenly spikes to\n",
    "> 500 MW in one region while weather is normal ‚Üí anomaly.\n",
    ">\n",
    "> **2. Short-Term Forecasting Model**\n",
    ">\n",
    "> ‚óè‚Äã Since data is **time-series with seasonality (daily, weekly) +\n",
    "> external factors** **(weather)**:‚Äã\n",
    ">\n",
    "> ‚óã‚Äã **ARIMA** ‚Üí handles trend, no seasonality.‚Äã  \n",
    "> ‚óã‚Äã **SARIMA** ‚Üí handles trend + seasonality.‚Äã  \n",
    "> ‚óã‚Äã **SARIMAX** ‚Üí handles trend + seasonality + external regressors\n",
    "> (like weather).‚Äã\n",
    ">\n",
    "> **Best fit here:SARIMAX** (because weather strongly impacts energy\n",
    "> usage). Example: Forecast next 1‚Äì3 hours (4‚Äì12 intervals) of demand\n",
    "> for scheduling power generation.\n",
    ">\n",
    "> **3. Validation & Monitoring**  \n",
    "> ‚óè‚Äã **Validation during training:‚Äã**  \n",
    "> ‚óã‚Äã Use **rolling forecast origin (walk-forward validation)** instead of\n",
    "> simple train/test split.‚Äã  \n",
    "> ‚óã‚Äã Metrics: **MAE, RMSE, MAPE** for forecast accuracy.‚Äã  \n",
    "> ‚óè‚Äã **Monitoring in production:‚Äã**  \n",
    "> ‚óã‚Äã Track **forecast error over time** (drift detection).‚Äã  \n",
    "> ‚óã‚Äã Re-train model periodically (weekly/monthly).‚Äã  \n",
    "> ‚óã‚Äã Monitor anomaly detection **false positives/negatives**.‚Äã\n",
    "\n",
    "Example: If the model consistently underestimates peak hours, retrain\n",
    "with latest data.\n",
    "\n",
    "> **4. Business Value & Operations Impact**  \n",
    "> ‚óè‚Äã **For Grid Stability:‚Äã**  \n",
    "> ‚óã‚Äã Detect abnormal spikes/drops ‚Üí avoid **blackouts** or **equipment**\n",
    "> **overload**.‚Äã\n",
    ">\n",
    "> ‚óè‚Äã **For Power Generation Planning:‚Äã**  \n",
    "> ‚óã‚Äã Forecast demand ‚Üí schedule **power plants, renewable energy**\n",
    "> **integration, battery storage**.‚Äã  \n",
    "> ‚óè‚Äã **For Cost Optimization:‚Äã**  \n",
    "> ‚óã‚Äã Avoid overproduction or underproduction ‚Üí saves fuel, reduces\n",
    "> wastage.‚Äã‚óè‚Äã **For Customers & Policy Makers:‚Äã**  \n",
    "> ‚óã‚Äã Better demand-response programs (adjust pricing during peak hours).‚Äã\n",
    ">\n",
    "> Example: If anomaly detection finds sudden drop in one region ‚Üí could\n",
    "> mean equipment failure ‚Üí send alert to engineers.\n",
    ">\n",
    "> **Final Workflow Summary**  \n",
    "> 1.‚Äã **Ingest streaming data (Kafka, Spark Streaming, etc.).‚Äã**  \n",
    "> 2.‚Äã **Anomaly detection:** Isolation Forest (global anomalies), LOF\n",
    "> (contextual anomalies).‚Äã  \n",
    "> 3.‚Äã **Forecasting:** SARIMAX (uses seasonality + weather + region\n",
    "> features).‚Äã 4.‚Äã **Validation:** Walk-forward validation, RMSE/MAPE\n",
    "> tracking.‚Äã  \n",
    "> 5.‚Äã **Monitoring:** Error drift detection, periodic retraining.‚Äã  \n",
    "> 6.‚Äã **Business impact:** Prevent outages, optimize supply, reduce\n",
    "> costs, improve reliability."
   ],
   "id": "42a14256-91c8-446e-92a7-ab6bf11055d3"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
